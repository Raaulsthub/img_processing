{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting and Merging Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333 2000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./images/image.jpg')\n",
    "height, width = image.shape[:2]\n",
    "print(height, width)\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# separating channels\n",
    "(b, g, r) = cv2.split(image)\n",
    "cv2.imshow('blue to gray scale', b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# only blue\n",
    "image[:, :, 1] = 0\n",
    "image[:, :, 2] = 0\n",
    "cv2.imshow('only blue', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# merging channels\n",
    "merged_img = cv2.merge((b, g, r))\n",
    "cv2.imshow('merged again', merged_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# turning the blue chanel to zero\n",
    "merged_img[:, :, 0] = 0\n",
    "cv2.imshow('no blue', merged_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/image.jpg')\n",
    "\n",
    "# passing size\n",
    "resized_img = cv2.resize(image, (int(width/2), int(height/2)), interpolation=cv2.INTER_LINEAR)\n",
    "cv2.imshow('resized image', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# passing factor\n",
    "resized_img = cv2.resize(image, None, fx=0.2, fy=0.2, interpolation=cv2.INTER_AREA)\n",
    "# if we intent to enlarge the image, the best interpolation is cv2.INTER_CUBIC (time consuming) or cv2.INTER_LINEAR\n",
    "# if we intent to shrink the image, the usual is cv2.INTER_LINEAR\n",
    "cv2.imshow('resized image', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# there are other interpolation methods such as:\n",
    "# INTER_NEAREST (nearest neighbor)\n",
    "# INTER_LINEAR (bilinear interpolation)\n",
    "# INTER_AREA (resampling using pixel area relation)\n",
    "# INTER_CUBIC (bicubic interpolation)\n",
    "# INTER_LANCZOS4 (sinusoidal interpolation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create the transformation matrix (2 x 3)\n",
    "# M = np.float32([[1, 0, x], [0, 1, y]])\n",
    "# then we apply to the image\n",
    "# dst_image = cv2.warpAffine(image, M, (width, height)) # width and height refers to the output\n",
    "\n",
    "# translate an image 200 pixels in the x direction and 30 pixels in the y direction\n",
    "image = cv2.imread('./images/image.jpg')\n",
    "height, width = image.shape[:2]\n",
    "M = np.float32([[1, 0, 200], [0, 1, 30]])\n",
    "# to translate the other way, we use the negative x and y in the matrix\n",
    "\n",
    "dst_image = cv2.warpAffine(image, M, (width, height))\n",
    "\n",
    "cv2.imshow('Translated Image', dst_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = image.shape[:2]\n",
    "# 180 degrees, 1 means no scaling\n",
    "M = cv2.getRotationMatrix2D((width/2.0, height/2.0), 180, 1)\n",
    "dst_image = cv2.warpAffine(image, M, (width, height))\n",
    "cv2.imshow('rotated', dst_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_1 = np.float32([[450, 65], [517, 65], [431, 164], [552, 164]])\n",
    "pts_2 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]])\n",
    "M = cv2.getPerspectiveTransform(pts_1, pts_2)\n",
    "dst_image = cv2.warpPerspective(image, M, (height, width))\n",
    "cv2.imshow('warp perspective', dst_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# to correct perspective after image transformation, we need to create a transformation matrix\n",
    "# with 4 points of a quadrangle in both the raw and the transformed image (same quadrangle)\n",
    "# then we transform it\n",
    "# in execution the image i just created will be weird, because i didn't use the proper 8 points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image[80:200, 230:330]\n",
    "cv2.imshow('cropped image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
