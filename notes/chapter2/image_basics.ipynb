{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "## Image\n",
    "An image is composed of functions such as f(x, y) where x and y represent the coordinates of a pixel and f represents its information. In gray scale, this information (f) will be a number between 0 and 256 (8 bits) for example, showing how black the pixel is. In colored images, in the other hand, tree functions are needed, one for red scale, one for green and one for blue (r(x,y),g(x,y) and b(x,y)). In OpenCV, images are numpy arrays.\n",
    "\n",
    "## Resolution vs size\n",
    "An image with a resolution of 800x1200 is a grid of 800 columns and 1200 rows, containing 800 * 1200 = 960000 pixels. Knowing that does not mean that we know the physical dimentions of the image (one pixel does not mean 1 mm for example). How large a pixel (and how large an image are, consequently) will depend on the pixels per inch (PPI). Normaly PPI is set between 200 and 400.\n",
    "PPI = width(pixels) / width of image (inches) \n",
    "PPI = height(pixels) / height of imag\n",
    "\n",
    "## Formats and compression\n",
    "OpenCV supports the following formats: windows bitmap, jpeg, jpeg2000, png, portable image format and tiff files. The raw image is too big (in terms of data), so the formats will compress it. There are to main types of compression, the loss-less and the lossy. Loss-less algorithms will result in an equal image when decompressed, while the lossy, will loose some details.\n",
    "\n",
    "## Coordinates of pixels in OpenCV\n",
    "Upper-left -> (0, 0)\n",
    "\n",
    "## Important\n",
    "In  OpenCV, the the collors are in the BGR format, not rbg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing and manipulating pixels with OpenCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and showing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 600, 3)\n",
      "567000\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# loading image\n",
    "img = cv2.imread('./images/logo.png')\n",
    "\n",
    "# getting a tuple with the shape of the image and the number of collor chanels\n",
    "dimentions = img.shape\n",
    "print(dimentions)\n",
    "# how many elements (width * height * collor chanels)\n",
    "print(img.size)\n",
    "# dtype\n",
    "print(img.dtype)\n",
    "# showing img\n",
    "cv2.imshow('original image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() #close the image window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessing pixel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# getting all channels\n",
    "(b, g, r) = img[6, 40]\n",
    "print(b, g, r)\n",
    "# getting only blue from (BGR)\n",
    "print(img[6, 40, 0])\n",
    "# modifying\n",
    "img[6, 40] = (255, 255, 255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_left_corner = img[0:50, 0:50]\n",
    "# print(top_left_corner)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greyscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 600)\n",
      "189000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "grey_img = cv2.imread('./images/logo.png', cv2.IMREAD_GRAYSCALE)\n",
    "print(grey_img.shape)\n",
    "print(grey_img.size)\n",
    "cv2.imshow('grey image', grey_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# get pixel info\n",
    "print(grey_img[6, 40])\n",
    "# set it to black\n",
    "grey_img[6, 40] = 0\n",
    "# painting subset of the image\n",
    "grey_img[0:50, 0:50] = np.full((50, 50), 255)\n",
    "cv2.imshow(\"painted white grey image\", grey_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
